{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Assignment 08\n",
    "\n",
    "#### Submitted By:\n",
    "1. Dhruvan Ganesh\n",
    "2. Sheikh Mastura Farzana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Environment Information\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Device Name: GeForce GTX 1660 Ti\n",
      "Set Random Seed: 42\n",
      "Data Dir: ~/.datasets\n"
     ]
    }
   ],
   "source": [
    "import torch.cuda\n",
    "from pytorch_lightning import seed_everything\n",
    "from torch import device\n",
    "\n",
    "device = device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "seed = 42\n",
    "seed_everything(seed)\n",
    "print(\"Set Random Seed:\", seed)\n",
    "\n",
    "data_dir = \"~/.datasets\"\n",
    "print(\"Data Dir:\", data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment8 (21 Aug 2020)\n",
    "---\n",
    "- Train a DCGAN for humanoid robot\n",
    "- Extra point for using WGAN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <span style=\"font-variant:small-caps\">Task 1: Train a DCGAN for Humanoid Robot</span>\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_kwargs(**kwargs):\n",
    "    return kwargs\n",
    "\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation=\"nearest\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# G(z)\n",
    "class Generator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=128, color_channels=1, latent_dim=100):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, d * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(d * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(d * 8, d * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(d * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(d * 4, d * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(d * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(d * 2, d, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(d),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(d, color_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        self.weight_init(mean=0.0, std=0.02)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=128, color_channels=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(color_channels, d, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(d, d * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(d * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(d * 2, d * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(d * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(d * 4, d * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(d * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(d * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        self.weight_init(mean=0.0, std=0.02)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x.view(-1, 1).squeeze(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class RobotModule(LightningModule):\n",
    "    def __init__(self, trainset_path: str, batch_size: int, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.preprocess = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(64),\n",
    "                transforms.CenterCrop(64),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        self.undo_preprocess = transforms.Normalize(\n",
    "            mean=[-0.485 / 0.229, -0.456 / 0.224, -0.406 / 0.225],\n",
    "            std=[1 / 0.229, 1 / 0.224, 1 / 0.225],\n",
    "        )\n",
    "\n",
    "        self.trainset = datasets.ImageFolder(\n",
    "            root=trainset_path, transform=self.preprocess\n",
    "        )\n",
    "        self.classes = self.trainset.classes\n",
    "        self.batch_size = batch_size\n",
    "        self.color_channels = 3\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        loader = DataLoader(\n",
    "            self.trainset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=4,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        return loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torchvision\n",
    "\n",
    "\n",
    "def make_grid(tensors=(), idxs=()):\n",
    "    out_tensors = []\n",
    "    for tensor in tensors:\n",
    "        for idx in idxs:\n",
    "            out_tensors.append(tensor[idx])\n",
    "    return out_tensors\n",
    "\n",
    "\n",
    "class DCGAN(RobotModule):\n",
    "    def __init__(self, batch_size, **kwargs):\n",
    "        super().__init__(batch_size=batch_size, **kwargs)\n",
    "        self.batch_size = batch_size\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        self.generator = Generator(\n",
    "            64, color_channels=self.color_channels, latent_dim=self.latent_dim\n",
    "        )\n",
    "        self.discriminator = Discriminator(64, color_channels=self.color_channels)\n",
    "\n",
    "        # cache for generated images\n",
    "        self.generated_imgs = None\n",
    "        self.last_imgs = None\n",
    "\n",
    "        self.adversarial_loss = nn.BCELoss()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt_g = torch.optim.Adam(\n",
    "            self.generator.parameters(), lr=0.0002, betas=(0.5, 0.999)\n",
    "        )\n",
    "        opt_d = torch.optim.Adam(\n",
    "            self.discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999)\n",
    "        )\n",
    "        return [opt_g, opt_d], []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.generator(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        imgs, _ = batch\n",
    "\n",
    "        # sample noise\n",
    "        z = torch.randn(imgs.shape[0], self.latent_dim, 1, 1)\n",
    "        z = z.type_as(imgs)\n",
    "\n",
    "        # train generator\n",
    "        if optimizer_idx == 0:\n",
    "\n",
    "            # generate images\n",
    "            self.generated_imgs = self(z)\n",
    "\n",
    "            # log sampled images\n",
    "            sample_imgs = self.generated_imgs[:16]\n",
    "            grid = torchvision.utils.make_grid(sample_imgs, nrow=4, normalize=True)\n",
    "            torchvision.utils.save_image(\n",
    "                grid, f\"/tmp/gan-gen-img-{self.current_epoch}.jpg\"\n",
    "            )\n",
    "            self.logger.experiment.add_image(\"generated_images\", grid, 0)\n",
    "\n",
    "            # ground truth result (ie: all fake)\n",
    "            # put on GPU because we created this tensor inside training_loop\n",
    "            valid = torch.ones(imgs.size(0), 1)\n",
    "            valid = valid.type_as(imgs)\n",
    "\n",
    "            # adversarial loss is binary cross-entropy\n",
    "            g_loss = self.adversarial_loss(self.discriminator(self(z)), valid)\n",
    "            tqdm_dict = {\"loss_g\": g_loss}\n",
    "            output = OrderedDict(\n",
    "                {\"loss\": g_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict}\n",
    "            )\n",
    "            return output\n",
    "\n",
    "        # train discriminator\n",
    "        if optimizer_idx == 1:\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "\n",
    "            # how well can it label as real?\n",
    "            valid = torch.ones(imgs.size(0), 1)\n",
    "            valid = valid.type_as(imgs)\n",
    "\n",
    "            real_loss = self.adversarial_loss(self.discriminator(imgs), valid)\n",
    "\n",
    "            # how well can it label as fake?\n",
    "            fake = torch.zeros(imgs.size(0), 1)\n",
    "            fake = fake.type_as(imgs)\n",
    "\n",
    "            fake_loss = self.adversarial_loss(\n",
    "                self.discriminator(self(z).detach()), fake\n",
    "            )\n",
    "\n",
    "            # discriminator loss is the average of these\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            tqdm_dict = {\"loss_d\": d_loss}\n",
    "            output = OrderedDict(\n",
    "                {\"loss\": d_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict}\n",
    "            )\n",
    "            return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                 | Type            | Params\n",
      "-----------------------------------------------------\n",
      "0  | generator            | Generator       | 3 M   \n",
      "1  | generator.net        | Sequential      | 3 M   \n",
      "2  | generator.net.0      | ConvTranspose2d | 819 K \n",
      "3  | generator.net.1      | BatchNorm2d     | 1 K   \n",
      "4  | generator.net.2      | ReLU            | 0     \n",
      "5  | generator.net.3      | ConvTranspose2d | 2 M   \n",
      "6  | generator.net.4      | BatchNorm2d     | 512   \n",
      "7  | generator.net.5      | ReLU            | 0     \n",
      "8  | generator.net.6      | ConvTranspose2d | 524 K \n",
      "9  | generator.net.7      | BatchNorm2d     | 256   \n",
      "10 | generator.net.8      | ReLU            | 0     \n",
      "11 | generator.net.9      | ConvTranspose2d | 131 K \n",
      "12 | generator.net.10     | BatchNorm2d     | 128   \n",
      "13 | generator.net.11     | ReLU            | 0     \n",
      "14 | generator.net.12     | ConvTranspose2d | 3 K   \n",
      "15 | generator.net.13     | Tanh            | 0     \n",
      "16 | discriminator        | Discriminator   | 2 M   \n",
      "17 | discriminator.net    | Sequential      | 2 M   \n",
      "18 | discriminator.net.0  | Conv2d          | 3 K   \n",
      "19 | discriminator.net.1  | LeakyReLU       | 0     \n",
      "20 | discriminator.net.2  | Conv2d          | 131 K \n",
      "21 | discriminator.net.3  | BatchNorm2d     | 256   \n",
      "22 | discriminator.net.4  | LeakyReLU       | 0     \n",
      "23 | discriminator.net.5  | Conv2d          | 524 K \n",
      "24 | discriminator.net.6  | BatchNorm2d     | 512   \n",
      "25 | discriminator.net.7  | LeakyReLU       | 0     \n",
      "26 | discriminator.net.8  | Conv2d          | 2 M   \n",
      "27 | discriminator.net.9  | BatchNorm2d     | 1 K   \n",
      "28 | discriminator.net.10 | LeakyReLU       | 0     \n",
      "29 | discriminator.net.11 | Conv2d          | 8 K   \n",
      "30 | discriminator.net.12 | Sigmoid         | 0     \n",
      "31 | adversarial_loss     | BCELoss         | 0     \n",
      "/home/navrudh/Apps/miniconda3/envs/cudavision/lib/python3.8/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1475782e600d46308ad041e917cfb07c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%tensorboard --logdir lightning_logs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "gan_model = DCGAN(batch_size=32, trainset_path=\"minimal_dataset/\")\n",
    "\n",
    "trainer = Trainer(gpus=1, max_epochs=200, checkpoint_callback=False,)\n",
    "trainer.fit(gan_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}